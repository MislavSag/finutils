% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/qc_hour_parquet.R
\name{qc_hour_parquet}
\alias{qc_hour_parquet}
\title{Process and Clean Quantconnect Hour Price Data}
\usage{
qc_hour_parquet(
  file_path,
  etfs = NULL,
  symbols = NULL,
  first_date = NULL,
  min_obs = 253,
  duplicates = c("slow", "fast", "none"),
  price_threshold = 1e-08,
  market_symbol = NULL,
  add_dv_rank = TRUE
)
}
\arguments{
\item{file_path}{Character. Path to the CSV file containing the price data.}

\item{etfs}{Character. Can be TRUE (only ETF's), FALSE (only non ETF's),
character (ETF constituents we want to follow) or NULL (all equities).
IMPORTANT. This is relevant only from date 2009-08.}

\item{symbols}{Character. Symbols to include in the analysis. Default is NULL, which means all symbols are included.}

\item{first_date}{Date. The first date to include in the analysis. Default is NULL, which means all dates are included.}

\item{min_obs}{Integer. Minimum number of observations required per symbol. Default is 253.}

\item{duplicates}{Character. Method for handling duplicate symbols. Options are "slow", "fast", or "none". Default is "slow".}

\item{price_threshold}{Numeric. Minimum allowed price for open, high, low, and close columns. Default is 1e-8.}

\item{market_symbol}{Character. Symbol representing the market index (e.g., "spy").
Default is NULL, which means you don't want to use add market data.}

\item{add_dv_rank}{Logical. Whether to add a rank by dollar volume for every date. Default is TRUE.}
}
\value{
A cleaned and processed data.table with price and return information.
}
\description{
This function processes raw hour price data, adjusts for splits/dividends, calculates
returns, and removes duplicates and invalid data points.
}
